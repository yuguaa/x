---
group:
  title: æ¨¡å‹æ¥å…¥
  order: 1
title: é€šä¹‰åƒé—®
order: 1
---

è¿™ç¯‡æŒ‡å—å°†ä»‹ç»å¦‚ä½•åœ¨ä½¿ç”¨ Ant Design X æ­å»ºçš„åº”ç”¨ä¸­æ¥å…¥ Qwen æä¾›çš„æ¨¡å‹æœåŠ¡ã€‚

Qwen çš„æ¨¡å‹æ¨ç†æœåŠ¡æ”¯æŒã€Œå…¼å®¹ OpenAI æ¨¡å¼ã€ã€‚è¯¦è§å®˜æ–¹æ–‡æ¡£: [é˜¿é‡Œäº‘ - é€šä¹‰åƒé—®](https://help.aliyun.com/zh/model-studio/developer-reference/compatibility-of-openai-with-dashscope)

### ç›¸å…³å‚æ•°è·å–

- å¦‚ä½•è·å– baseURL - <https://help.aliyun.com/zh/model-studio/getting-started/what-is-model-studio>
- å¦‚ä½•è·å– API Key - <https://help.aliyun.com/zh/model-studio/developer-reference/get-api-key>
- æ¨¡å‹åˆ—è¡¨ - <https://help.aliyun.com/zh/model-studio/getting-started/models>

### ä»€ä¹ˆæ˜¯ã€Œå…¼å®¹ OpenAI æ¨¡å¼ã€ï¼Ÿ

æ˜¯æŒ‡åœ¨æ¥å£è®¾è®¡å’Œä½¿ç”¨æ–¹å¼ä¸Šä¸ OpenAI çš„ API ä¿æŒä¸€è‡´çš„æ¨¡å‹æ¨ç†æœåŠ¡ã€‚

è¿™æ„å‘³ç€å¼€å‘è€…å¯ä»¥ä½¿ç”¨ä¸è°ƒç”¨ OpenAI æ¨¡å‹ç›¸åŒçš„ä»£ç å’Œæ–¹æ³•ï¼Œæ¥è°ƒç”¨è¿™äº›å…¼å®¹æœåŠ¡ï¼Œä»è€Œå‡å°‘å¼€å‘æ¥å…¥æˆæœ¬ã€‚

## ä½¿ç”¨ X SDK æ¥å…¥

ä½¿ç”¨URLæ¥å…¥æ¨¡å‹æ˜¯ X SDKæä¾›çš„åŸºç¡€èƒ½åŠ›ï¼Œè¯¦æƒ…è¯·æŸ¥çœ‹[X SDK](/sdks/introduce-cn)ã€‚

### ç¤ºä¾‹

<code src="./demo/qwen-sdk.tsx" title="ä½¿ç”¨X SDKæ¥å…¥"></code>

## ä½¿ç”¨ openai-node å…¼å®¹è°ƒç”¨

> æ³¨æ„: ğŸ”¥ `dangerouslyAllowBrowser` å­˜åœ¨å®‰å…¨é£é™©ï¼Œå¯¹æ­¤ openai-node çš„å®˜æ–¹æ–‡æ¡£æœ‰è¯¦ç»†çš„[è¯´æ˜](https://github.com/openai/openai-node?tab=readme-ov-file#requirements)ã€‚

```tsx
import { Bubble, BubbleListProps, Sender } from '@ant-design/x';
import {
  AbstractXRequestClass,
  OpenAIChatProvider,
  SSEFields,
  useXChat,
  XModelMessage,
  XModelParams,
  XRequestOptions,
} from '@ant-design/x-sdk';
import { Flex } from 'antd';
import OpenAI from 'openai';
import React, { useState } from 'react';

type OutputType = Partial<Record<SSEFields, any>>;
type InputType = XModelParams;

class OpenAiRequest<
  Input extends InputType = InputType,
  Output extends OutputType = OutputType,
> extends AbstractXRequestClass<Input, Output> {
  client: any;
  stream: OpenAI | undefined;

  _isTimeout = false;
  _isStreamTimeout = false;
  _isRequesting = false;

  constructor(baseURL: string, options: XRequestOptions<Input, Output>) {
    super(baseURL, options);
    this.client = new OpenAI({
      baseURL: 'https://dashscope.aliyuncs.com/compatible-mode/v1',
      apiKey: 'OPENAI_API_KEY',
      dangerouslyAllowBrowser: true,
    });
  }
  get asyncHandler(): Promise<any> {
    return Promise.resolve();
  }
  get isTimeout(): boolean {
    return this._isTimeout;
  }
  get isStreamTimeout(): boolean {
    return this._isStreamTimeout;
  }
  get isRequesting(): boolean {
    return this._isRequesting;
  }
  get manual(): boolean {
    return true;
  }
  async run(input: Input): Promise<void> {
    const { callbacks } = this.options;
    try {
      await this.client.responses.create({
        model: 'qwen-plus',
        messages: input?.messages || [],
        stream: true,
      });

      // è¯·åŸºäº response å®ç° æµæ•°æ®æ›´æ–°é€»è¾‘
      // Please implement stream data update logic based on response
    } catch (error: any) {
      callbacks?.onError(error);
    }
  }
  abort(): void {
    // è¯·åŸºäºopenai å®ç° abort
    // Please implement abort based on OpenAI
  }
}

const provider = new OpenAIChatProvider<XModelMessage, InputType, OutputType>({
  request: new OpenAiRequest('OPENAI', {}),
});

const Demo: React.FC = () => {
  const [content, setContent] = useState('');
  const { onRequest, messages, isRequesting, abort } = useXChat({
    provider,
    requestPlaceholder: () => {
      return {
        content: 'loading...',
        role: 'assistant',
      };
    },
    requestFallback: (_, { error }) => {
      if (error.name === 'AbortError') {
        return {
          content: 'Request is aborted',
          role: 'assistant',
        };
      }
      return {
        content: error?.toString(),
        role: 'assistant',
      };
    },
  });

  const items = messages.map(({ message, id }) => ({
    key: id,
    ...message,
  }));

  const role: BubbleListProps['role'] = {
    assistant: {
      placement: 'start',
    },
    user: { placement: 'end' },
  };

  return (
    <Flex
      vertical
      justify="space-between"
      style={{
        height: 400,
        padding: 16,
      }}
    >
      <Bubble.List role={role} items={items} />
      <Sender
        value={content}
        onChange={setContent}
        loading={isRequesting}
        onCancel={abort}
        onSubmit={(val) => {
          onRequest({
            messages: [{ role: 'user', content: val }],
          });
          setContent('');
        }}
      />
    </Flex>
  );
};

export default Demo;
```

### ç¤ºä¾‹

<code src="./demo/qwen.tsx" title="ä½¿ç”¨ openai æ¥å…¥qwen" description="æ­¤ç¤ºä¾‹ä»…å±•ç¤ºä½¿ç”¨X SDKæ¥å…¥ openai çš„é€»è¾‘å‚è€ƒï¼Œå¹¶æœªå¯¹æ¨¡å‹æ•°æ®è¿›è¡Œå¤„ç†ï¼Œéœ€å¡«å†™æ­£ç¡®çš„apiKeyå†è¿›è¡Œæ•°æ®è°ƒè¯•"></code>
